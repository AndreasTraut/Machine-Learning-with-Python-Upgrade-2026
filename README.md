# Machine Learning with Python - Upgrade 2025

ğŸ‘¨â€ğŸ’» **Autor:** Andreas Traut  
ğŸ“… **Datum:** Dezember 2025 / Januar 2026  
ğŸ·ï¸ **Version:** 2025.1

---

## ğŸ“‹ Inhaltsverzeichnis

- [ğŸ¯ Ãœber dieses Repository](#-Ã¼ber-dieses-repository)
- [ğŸ“ Ordnerstruktur](#-ordnerstruktur)
- [ğŸ” Ziele: Small Data vs. Big Data](#-ziele-small-data-vs-big-data)
- [ğŸš€ Quickstart](#-quickstart)
- [ğŸ“¦ UnterstÃ¼tzte Versionen](#-unterstÃ¼tzte-versionen)
- [âœ¨ Was wurde aktualisiert?](#-was-wurde-aktualisiert)
- [ğŸ”„ Machine Learning Workflow](#-machine-learning-workflow)
- [ğŸ“š Dateien in diesem Repository](#-dateien-in-diesem-repository)
- [ğŸ”§ Installation & Setup](#-installation--setup)
- [ğŸ” Reproduzierbarkeit](#-reproduzierbarkeit)
- [ğŸ“Š Datenquellen](#-datenquellen)
- [ğŸ“š Weitere Ressourcen](#-weitere-ressourcen)
- [ğŸ“ Lizenz & BeitrÃ¤ge](#-lizenz--beitrÃ¤ge)

## ğŸ¯ Ãœber dieses Repository

Dieses Repository enthÃ¤lt modernisierte Machine-Learning-Beispiele, aktualisiert nach den Best Practices von 2025/2026. Die **ursprÃ¼nglichen Dateien** wurden in den Ordner `/legacy/` verschoben â€“ alle aktualisierten Versionen befinden sich in den Hauptordnern.

## ğŸ“ Ordnerstruktur

```
Machine-Learning-with-Python-Upgrade-2026/
â”œâ”€â”€ README.md                 # Diese Datei - Hauptdokumentation
â”œâ”€â”€ CHANGELOG.md             # Dokumentation aller Ã„nderungen
â”œâ”€â”€ requirements.txt         # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ LICENSE                  # Lizenzinformationen
â”‚
â”œâ”€â”€ docs/                    # Detaillierte Projekt-Dokumentation
â”‚   â”œâ”€â”€ MOVIES_PREDICT_NANS.md          # Movies: NaN-Vorhersage
â”‚   â”œâ”€â”€ MOVIES_STRATIFIED_SAMPLE.md     # Movies: Stratified Sampling
â”‚   â”œâ”€â”€ AIRBNB_PRICE_PREDICTION.md      # AirBnB: Preisvorhersage
â”‚   â””â”€â”€ ML_WORKFLOW.md                  # ML-Workflow Leitfaden
â”‚
â”œâ”€â”€ notebooks/               # Jupyter Notebooks (modernisiert)
â”‚   â”œâ”€â”€ movies/             # Movies Machine Learning Beispiele
â”‚   â”‚   â”œâ”€â”€ Movies_Machine_Learning_Predict_NaNs.ipynb
â”‚   â”‚   â””â”€â”€ Movies_Machine_Learning_StratifiedSample.ipynb
â”‚   â””â”€â”€ iot/                # IoT Sensor Data Beispiele
â”‚
â”œâ”€â”€ scripts/                 # Python Scripts (modernisiert)
â”‚   â””â”€â”€ Sklearn_MachineLearning_AirBnB.py
â”‚
â”œâ”€â”€ datasets/                # DatensÃ¤tze
â”‚   â”œâ”€â”€ AirBnB/             # AirBnB Listings Daten
â”‚   â”œâ”€â”€ movies/             # Movies Database
â”‚   â”œâ”€â”€ environmental-sensor-data-132k/
â”‚   â””â”€â”€ TF-idf/
â”‚
â”œâ”€â”€ images/                  # Bilder fÃ¼r Notebooks
â”‚   â””â”€â”€ movies/
â”‚
â”œâ”€â”€ media/                   # Screenshots und Diagramme
â”‚
â””â”€â”€ legacy/                  # UrsprÃ¼ngliche Dateien (archiviert)
    â”œâ”€â”€ old_notebooks/      # Alte Jupyter Notebooks
    â”œâ”€â”€ old_scripts/        # Alte Python Scripts
    â””â”€â”€ iot-example/        # Altes IoT Beispiel
```

## ğŸ” Ziele: Small Data vs. Big Data

Dieses Repository demonstriert die **Unterschiede und Gemeinsamkeiten** zwischen **"Small Data"** (Scikit-Learn/Pandas) und **"Big Data"** (Spark) AnsÃ¤tzen im Machine Learning.

### ğŸ¯ Fokus des Repositories

Der Schwerpunkt liegt auf:

- âœ… Praktischen, wiederverwendbaren Code-Beispielen
- âœ… Vergleich von Scikit-Learn und Apache Spark ML
- âœ… VerstÃ¤ndnis der Unterschiede zwischen kleinen und groÃŸen DatensÃ¤tzen
- âœ… Verwendung von IDEs zusÃ¤tzlich zu Jupyter-Notebooks

### ğŸ“Š Small Data vs. Big Data im Detail

**Small Data (Scikit-Learn):**
- DatensÃ¤tze, die in den Arbeitsspeicher passen
- Einfache, schnelle Entwicklung
- Umfangreiche Bibliotheken (pandas, scikit-learn, matplotlib)
- Ideal fÃ¼r Prototyping und kleinere Projekte

**Big Data (Apache Spark):**
- Verteilte Verarbeitung groÃŸer DatensÃ¤tze
- Skalierbare Algorithmen
- Komplexere Infrastruktur
- FÃ¼r produktive, groÃŸe Anwendungen

## ğŸš€ Quickstart

### Lokale Installation mit venv

```bash
# Python Virtual Environment erstellen
python3 -m venv venv

# Environment aktivieren
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Dependencies installieren
pip install -r requirements.txt

# Python-Skript ausfÃ¼hren (aus dem Hauptverzeichnis)
python scripts/Sklearn_MachineLearning_AirBnB.py

# Jupyter Notebook starten
jupyter lab
# Dann die Notebooks im Ordner notebooks/movies/ Ã¶ffnen
```

### Mit Conda

```bash
# Conda Environment erstellen
conda create -n ml-python python=3.10
conda activate ml-python

# Dependencies installieren
pip install -r requirements.txt

# Oder mit conda:
conda install pandas numpy scikit-learn matplotlib seaborn jupyterlab
```

### Mit Docker

**Hinweis:** Die Beispiele sind fÃ¼r lokale AusfÃ¼hrung optimiert und benÃ¶tigen kein Docker. 

Ein Docker-Setup fÃ¼r die Spark-Beispiele ("Big Data") kÃ¶nnte separat erstellt werden. FÃ¼r die "Small Data" Beispiele in diesem Repository genÃ¼gt eine lokale Installation mit Python und den in `requirements.txt` aufgefÃ¼hrten Paketen.

## ğŸ“¦ UnterstÃ¼tzte Versionen

- **Python:** >= 3.10
- **pandas:** >= 2.0
- **numpy:** >= 1.24
- **scikit-learn:** >= 1.2
- **matplotlib:** >= 3.5
- **seaborn:** >= 0.12
- **jupyterlab:** >= 4.0
- **joblib:** >= 1.2

Siehe `requirements.txt` fÃ¼r genaue Versionsangaben.

## âœ¨ Was wurde aktualisiert?

### API-Ã„nderungen und Modernisierung

1. **OneHotEncoder:** `handle_unknown='ignore'` Parameter hinzugefÃ¼gt fÃ¼r robustere Verarbeitung unbekannter Kategorien
2. **SimpleImputer:** Moderne API statt veralteter `Imputer`
3. **ColumnTransformer:** Konsistente Verwendung fÃ¼r verschiedene Feature-Typen
4. **FunctionTransformer:** FÃ¼r benutzerdefinierte Transformationen
5. **LinearRegression:** Veralteter `normalize` Parameter entfernt (jetzt `StandardScaler` in Pipeline)

### Code-QualitÃ¤t

1. **F-Strings:** Statt `%s` oder `.format()` fÃ¼r bessere Lesbarkeit
2. **Type Hints:** Optional hinzugefÃ¼gt fÃ¼r bessere Code-Dokumentation
3. **Logging:** `logging` Modul statt `print()` Statements
4. **Modulare Struktur:** Funktionen statt langer Skripte
5. **Docstrings:** Klare Dokumentation aller Funktionen

### Reproduzierbarkeit

1. **random_state:** Konsequent in allen stochastischen Operationen gesetzt
2. **Seeds:** Dokumentiert und konsistent verwendet
3. **Versionierung:** Klare Angaben zu Package-Versionen

### Error Handling

1. Bessere Fehlerbehandlung beim Laden von Dateien
2. Klare Fehlermeldungen mit Hinweisen zur LÃ¶sung
3. Validierung von Eingabedaten

## ğŸ”„ Machine Learning Workflow

### 1. Daten einlesen

```python
import pandas as pd

def load_data(filepath: str) -> pd.DataFrame:
    """LÃ¤dt CSV-Datei und gibt DataFrame zurÃ¼ck."""
    return pd.read_csv(filepath)
```

### 2. Explorative Datenanalyse (EDA)

- Datenstruktur verstehen (`info()`, `describe()`)
- Visualisierungen erstellen (Histogramme, Scatter-Plots)
- Korrelationen analysieren
- Fehlende Werte identifizieren

### 3. Datenvorverarbeitung

**Fehlende Werte behandeln:**
```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="median")
# oder strategy="mean", "most_frequent", "constant"
```

**Kategorische Features encodieren:**
```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
```

**Numerische Features skalieren:**
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
```

### 4. Pipeline aufbauen

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Numerische Pipeline
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),
    ('scaler', StandardScaler())
])

# Kategorische Pipeline
cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="most_frequent")),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# Kombinierte Pipeline
preprocessor = ColumnTransformer([
    ('num', num_pipeline, numeric_features),
    ('cat', cat_pipeline, categorical_features)
])
```

### 5. Modellwahl und Training

**Regression:**
```python
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
```

**Klassifikation:**
```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
```

### 6. Cross-Validation

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(
    model, X_train, y_train,
    cv=5,  # 5-fold cross-validation
    scoring='neg_mean_squared_error'
)
rmse_scores = np.sqrt(-scores)
```

### 7. Hyperparameter-Optimierung

**Grid Search:**
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    model, param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
```

**Randomized Search:**
```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_distributions = {
    'n_estimators': randint(10, 200),
    'max_depth': randint(5, 30)
}

random_search = RandomizedSearchCV(
    model, param_distributions,
    n_iter=20, cv=5,
    random_state=42
)
```

### 8. Evaluation

```python
from sklearn.metrics import mean_squared_error, r2_score

predictions = model.predict(X_test)
mse = mean_squared_error(y_test, predictions)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions)

print(f"RMSE: {rmse:.2f}")
print(f"RÂ²: {r2:.3f}")
```

### 9. Modell Persistenz

```python
import joblib

# Modell speichern
joblib.dump(best_model, 'model.pkl')

# Modell laden
loaded_model = joblib.load('model.pkl')
```

## ï¿½ Dateien in diesem Repository

### Notebooks

**[`notebooks/movies/Movies_Machine_Learning_Predict_NaNs.ipynb`](notebooks/movies/Movies_Machine_Learning_Predict_NaNs.ipynb)**
- Vorhersage fehlender Revenue-Werte in Movies-Dataset
- Zeigt Umgang mit Missing Data
- DecisionTree und RandomForest Regressoren

**[`notebooks/movies/Movies_Machine_Learning_StratifiedSample.ipynb`](notebooks/movies/Movies_Machine_Learning_StratifiedSample.ipynb)**
- Stratifiziertes Sampling fÃ¼r ausgewogene Train/Test-Splits
- Vergleich verschiedener Sampling-Strategien
- Pipeline-Erstellung und Cross-Validation

**[`scripts/Sklearn_MachineLearning_AirBnB.py`](scripts/Sklearn_MachineLearning_AirBnB.py)**
- VollstÃ¤ndiger Machine-Learning-Workflow fÃ¼r AirBnB-Preisvorhersage
- Zeigt Best Practices: modularer Aufbau, Type Hints, Logging
- Hyperparameter-Optimierung mit GridSearch und RandomizedSearch
- Verwendung in IDEs wie Spyder oder PyCharm empfohlen

---

> â¡ï¸ **Detaillierte Projekt-Dokumentationen:** Siehe [`docs/`](docs/) Verzeichnis fÃ¼r ausfÃ¼hrliche Beschreibungen

**ğŸ“ Projekt-Guides:**
- **[Movies: Vorhersage fehlender Revenue-Werte](docs/MOVIES_PREDICT_NANS.md)** - ML statt Imputation fÃ¼r NaN-Werte
- **[Movies: Stratified Sampling](docs/MOVIES_STRATIFIED_SAMPLE.md)** - ReprÃ¤sentative Train/Test-Splits erstellen
- **[AirBnB: Preisvorhersage](docs/AIRBNB_PRICE_PREDICTION.md)** - VollstÃ¤ndiger ML-Workflow mit Best Practices

**ğŸ“– LeitfÃ¤den:**
- **[Machine Learning Workflow](docs/ML_WORKFLOW.md)** - Schritt-fÃ¼r-Schritt Anleitung (9 Phasen)

---

### Konfiguration

**[`requirements.txt`](requirements.txt)**
- Minimale empfohlene Versionen aller Dependencies
- FÃ¼r reproduzierbare Umgebungen

**[`CHANGELOG.md`](CHANGELOG.md)**
- Detaillierte Liste aller Ã„nderungen
- BegrÃ¼ndung fÃ¼r Updates

### Legacy

Die ursprÃ¼nglichen Dateien befinden sich im Ordner [`legacy/`](legacy/):
- [`legacy/old_notebooks/`](legacy/old_notebooks/) - Alte Jupyter Notebooks
- [`legacy/old_scripts/`](legacy/old_scripts/) - Alte Python Scripts  
- [`legacy/iot-example/`](legacy/iot-example/) - IoT Sensor Data Beispiel

## ï¿½ Installation & Setup

### Voraussetzungen

- Python 3.10 oder hÃ¶her
- pip oder conda Package Manager
- Git (fÃ¼r Repository-Clone)

### Schritt-fÃ¼r-Schritt Anleitung

**1. Repository klonen:**
```bash
git clone https://github.com/AndreasTraut/Machine-Learning-with-Python-Upgrade-2026.git
cd Machine-Learning-with-Python-Upgrade-2026
```

**2. Virtuelle Umgebung erstellen (empfohlen):**

```bash
# Mit venv (Python Standard)
python -m venv venv

# Aktivieren:
# Windows:
venv\Scripts\activate
# Linux/macOS:
source venv/bin/activate
```

**3. Dependencies installieren:**
```bash
pip install -r requirements.txt
```

**4. Datasets herunterladen:**
- **AirBnB:** [Inside Airbnb](http://insideairbnb.com/get-the-data.html) â†’ Speichern unter `datasets/AirBnB/listings.csv`
- **Movies:** [Kaggle IMDB](https://www.kaggle.com/datasets) â†’ Speichern unter `datasets/movies/movies.csv`

**5. Notebooks oder Scripts ausfÃ¼hren:**
```bash
# Jupyter Lab starten
jupyter lab

# Oder Python Script direkt ausfÃ¼hren
python scripts/Sklearn_MachineLearning_AirBnB.py
```

### IDE-Setup (optional)

FÃ¼r die Arbeit mit den Python Scripts empfehlen wir:

- **[Spyder IDE](https://www.spyder-ide.org/)** - Teil von Anaconda
- **[PyCharm](https://www.jetbrains.com/pycharm/)** - Professional oder Community
- **[VS Code](https://code.visualstudio.com/)** - Mit Python Extension

**VS Code Extensions:**
- Python (Microsoft)
- Jupyter (Microsoft)
- Pylance (Microsoft)

## ï¿½ğŸ” Reproduzierbarkeit

FÃ¼r reproduzierbare Ergebnisse:

1. **random_state setzen:**
   ```python
   # In train_test_split
   train_test_split(X, y, test_size=0.2, random_state=42)
   
   # In Modellen
   RandomForestRegressor(n_estimators=100, random_state=42)
   
   # In Cross-Validation
   cross_val_score(model, X, y, cv=5, random_state=42)
   
   # In Grid/Randomized Search
   GridSearchCV(model, param_grid, cv=5, random_state=42)
   ```

2. **Numpy seed setzen:**
   ```python
   import numpy as np
   np.random.seed(42)
   ```

3. **Exakte Versionen verwenden:**
   ```bash
   pip freeze > requirements-exact.txt
   ```

## ğŸ“Š Datenquellen

### AirBnB Dataset
- **Quelle:** [Inside Airbnb](http://insideairbnb.com/get-the-data.html)
- **Lizenz:** Creative Commons CC0 1.0 Universal "Public Domain Dedication"
- **Pfad:** `datasets/AirBnB/listings.csv`

### Movies Dataset
- **Quelle:** [Kaggle - IMDB Movies](https://www.kaggle.com/datasets)
- **Pfad:** `datasets/movies/`

**Hinweis:** Die Datasets mÃ¼ssen separat heruntergeladen werden. Die Skripte geben klare Anweisungen, falls Daten fehlen.

## ğŸ“š Weitere Ressourcen

### Dokumentation
- [Scikit-Learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/)

### Tutorials
- [Scikit-Learn Tutorials](https://scikit-learn.org/stable/tutorial/index.html)
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)

## ğŸ“ Lizenz & BeitrÃ¤ge

### Lizenz

Dieses Werk ist lizenziert unter der **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License**.

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](http://creativecommons.org/licenses/by-nc-sa/4.0/)

**Was bedeutet das?**
- âœ… Sie dÃ¼rfen das Material teilen und bearbeiten
- âœ… Angemessene Nennung des Urhebers erforderlich
- âŒ Keine kommerzielle Nutzung
- âœ… Weitergabe unter gleichen Bedingungen

Um eine Kopie dieser Lizenz zu sehen, besuchen Sie:
http://creativecommons.org/licenses/by-nc-sa/4.0/

### BeitrÃ¤ge

Dieses Upgrade wurde erstellt, um die Code-Beispiele auf aktuelle Best Practices zu bringen.

**Feedback und Verbesserungen willkommen!**

- ğŸ› **Issues:** Melden Sie Fehler oder schlagen Sie Verbesserungen vor
- ğŸ’¡ **Diskussionen:** Teilen Sie Ihre Ideen und Fragen
- ğŸ”§ **Pull Requests:** BeitrÃ¤ge sind herzlich willkommen

**Kontakt:**
- GitHub: [@AndreasTraut](https://github.com/AndreasTraut)
- LinkedIn: [Andreas Traut](https://www.linkedin.com/in/andreas-traut)

---

**UrsprÃ¼ngliches Repository:** [AndreasTraut/Machine-Learning-with-Python](https://github.com/AndreasTraut/Machine-Learning-with-Python)
