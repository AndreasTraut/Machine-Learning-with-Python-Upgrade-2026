# ğŸš€ Machine Learning with Python â€” Upgrade 2026

**Vom Legacy-Code (2020) zu modernen Best Practices**

- **Autor:** Andreas Traut
- **Stand:** Januar 2026
- **Version:** 2026.1

## ğŸ“– Ãœber dieses Projekt

Dieses Repository fasst die Evolution eines Machine-Learning-Workflows von 2020 bis 2026 zusammen. Ziel ist es, alten Code nicht nur lauffÃ¤hig zu halten, sondern ihn gemÃ¤ÃŸ moderner Software-Engineering-Prinzipien (ModularitÃ¤t, Typisierung, Pipelines, Logging) zu refactoren und zu dokumentieren.

Die Originaldateien sind archiviert; der neuen Code demonstriert praktikable Patterns fÃ¼r Produktion und Forschung.

## ğŸ”„ Evolution: 2020 vs. 2026 (Kurzvergleich)

| Feature | 2020 â€” Legacy | 2026 â€” Upgrade |
|---|---:|:---|
| Code-Struktur | Monolithische Skripte & Notebooks | Modulare Pakete, `if __name__ == "__main__"` |
| Daten-Pipelines | Manuelle Schritte (fillna, get_dummies) | `sklearn.pipeline.Pipeline`, `ColumnTransformer` |
| Typisierung | Dynamisch (keine Type Hints) | Typ-Hints (z. B. `pd.DataFrame` â†’ `-> pd.DataFrame`) |
| Konfiguration | Hardcoded Pfade & Parameter | Zentralisierte Konfiguration & Konstanten |
| Logging | Viele `print()` | Professionelles `logging`-Modul |
| Reproduzierbarkeit | Sporadisches `random_state` | Konsequentes Seeding & genaue `requirements.txt` |
| Fehlerbehandlung | Kaum vorhanden | Validierung, `try/except`-BlÃ¶cke |

## ğŸ“‹ Inhaltsverzeichnis

- [Ziele: Small Data vs. Big Data](#ziele-small-data-vs-big-data)
- [Projekt-Ãœbersicht & Ordnerstruktur](#projekt-%C3%BCbersicht--ordnerstruktur)
- [Technischer Stack](#technischer-stack)
- [Installation & Quickstart](#installation--quickstart)
- [Fallstudien (Case Studies)](#fallstudien-case-studies)
- [ML-Workflow 2026](#ml-workflow-2026)
- [Lizenz & Credits](#lizenz--credits)

## ğŸ” Ziele: Small Data vs. Big Data

Small Data (scikit-learn / pandas): Inâ€‘Memory-Verarbeitung, komplexes Feature-Engineering, schnelle Iteration â€” ideal fÃ¼r DatensÃ¤tze, die in den Arbeitsspeicher passen (z. B. AirBnB-Listings).

Big Data (Apache Spark): Skalierbarkeit und verteiltes Rechnen. Spark-Beispiele werden in separaten Docker-Containern gehalten, um lokale Setups schlank zu halten.

## ğŸ“ Projekt-Ãœbersicht & Ordnerstruktur

Die Struktur trennt klar zwischen modernem Code und archiviertem Legacy-Material:

```
Machine-Learning-with-Python-Upgrade-2026/
â”œâ”€â”€ README-UPGRADE2026.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ docs/                    # Detaillierte Case-Study-Dokumentation
â”œâ”€â”€ datasets/                # Rohdaten (lokal)
â”œâ”€â”€ notebooks/               # Modernisierte Jupyter-Notebooks
â”œâ”€â”€ scripts/                 # Produktionsreife Skripte
â””â”€â”€ legacy/                  # Archiv (Originalcode 2020)
```

## ğŸ› ï¸ Technischer Stack

- Python: >= 3.10
- pandas: >= 2.0 (ggf. mit PyArrow-Backend)
- scikit-learn: >= 1.2 (z. B. `set_config(transform_output="pandas")`)
- Visualisierung: matplotlib, seaborn
- QualitÃ¤t: flake8-KonformitÃ¤t, Typ-Hints

## ğŸš€ Installation & Quickstart

Empfohlen: `venv` fÃ¼r eine isolierte Umgebung.

1) Repository klonen

```bash
git clone https://github.com/AndreasTraut/Machine-Learning-with-Python-Upgrade-2026.git
cd Machine-Learning-with-Python-Upgrade-2026
```

2) Virtuelle Umgebung erstellen

```bash
python -m venv venv
```

3) Aktivieren

- Windows (PowerShell):

```powershell
venv\Scripts\Activate.ps1
```

- Windows (cmd):

```cmd
venv\Scripts\activate.bat
```

- macOS / Linux:

```bash
source venv/bin/activate
```

4) AbhÃ¤ngigkeiten installieren

```bash
pip install -r requirements.txt
```

5) Beispielskript ausfÃ¼hren (AirBnB)

```bash
python scripts/Sklearn_MachineLearning_AirBnB.py
```

## ğŸ³ Docker Environment & Big Data

FÃ¼r die **Big Data Beispiele (PySpark)** wird eine vorkonfigurierte Docker-Umgebung genutzt, um eine reibungslose AusfÃ¼hrung ohne komplexe lokale Installationen zu gewÃ¤hrleisten.

- **ğŸ—ï¸ Infrastruktur:** Detaillierter Einblick in den Tech-Stack (Java/Spark/Python Layer) innerhalb des Containers:  
  ğŸ‘‰ **[Technische Architektur & Docker Details lesen](./docs/DOCKER_INFO.md)**

- **ğŸ”¬ Deep Dive:** Anwendung der Umgebung am Beispiel Text Mining (TF-IDF & K-Means):  
  ğŸ‘‰ **[PySpark Clustering Workflow ansehen](./docs/PYSPARK_TFIDF.md)**


## ğŸ“š Fallstudien (Case Studies)

1) **AirBnB â€” Preisvorhersage (Full ML Pipeline)**

- Pfad: `scripts/Sklearn_MachineLearning_AirBnB.py`
- Fokus: ColumnTransformer, iterative Imputer, robustes Logging
- Doku: `docs/AIRBNB_PRICE_PREDICTION.md`

2) **Movies â€” Predicting NaNs**

- Pfad: `notebooks/movies/`
- Fokus: MLâ€‘gestÃ¼tzte Imputation (DecisionTrees), Stratified vs. Random Sampling
- Doku: `docs/MOVIES_PREDICT_NANS.md`

## ğŸ”„ ML-Workflow 2026

- Ingestion: typâ€‘sicheres Laden mit Validierung
- EDA: Verteilungen, Korrelationen, Visual Checks
- Preprocessing: Categorical â†’ OneHot (handle_unknown='ignore'), Numerical â†’ Scaler + Imputer
- Training: GridSearch / RandomizedSearch
- Evaluation: RMSE, RÂ², Residual-Analyse
- Persistenz: Modell speichern mit `joblib`

## ğŸ“ Lizenz & Credits

Dieses Projekt basiert auf dem ursprÃ¼nglichen Werk von Andreas Traut.

Lizenz: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0).

Feedback, Issues und Pull Requests sind willkommen.
