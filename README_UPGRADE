üöÄ Machine Learning with Python ‚Äì Upgrade 2026
Vom Legacy-Code (2020) zu Modern Best Practices
üë®‚Äçüíª Autor: Andreas Traut
üìÖ Stand: Januar 2026
üè∑Ô∏è Version: 2026.1
üîó Original-Repository (2020): Machine-Learning-with-Python (Legacy)
üìñ √úber dieses Projekt: Die Evolution
Willkommen im Upgrade-Repository. Dieses Projekt ist mehr als nur eine Sammlung von Skripten ‚Äì es ist eine Dokumentation der Weiterentwicklung im Data Science Engineering √ºber die letzten f√ºnf Jahre.
Ich habe meine urspr√ºnglichen Projekte aus dem Jahr 2020 (basierend auf Python 3.7/3.8 und √§lteren Scikit-Learn Versionen) genommen und vollst√§ndig refactored. Ziel war es nicht nur, den Code lauff√§hig zu halten, sondern ihn auf das Niveau professioneller Software-Entwicklung im Jahr 2026 zu heben.
Die urspr√ºnglichen Dateien wurden archiviert, w√§hrend der neue Code moderne Standards wie Pipelines, Type Hinting und modulare Architektur demonstriert.
üîÑ Evolution: 2020 vs. 2026
Hier sehen Sie auf einen Blick, wie sich der Ansatz in diesem Repository ver√§ndert hat:
| Feature | ‚ùå Ansatz 2020 (Legacy) | ‚úÖ Ansatz 2026 (Upgrade) |
|---|---|---|
| Code-Struktur | Lange, monolithische Skripte & Notebooks | Modulare Funktionen, Kapselung, if __name__ == "__main__": |
| Daten-Pipelines | Manuelle Schritte (fillna, get_dummies) | Robuste sklearn.pipeline.Pipeline & ColumnTransformer |
| Typisierung | Dynamisch (keine Type Hints) | Statische Typisierung (def func(df: pd.DataFrame) -> None) |
| Konfiguration | Hardcoded Pfade & Parameter | Zentralisierte Konfiguration & Konstanten |
| Logging | Viele print() Statements | Professionelles logging Modul |
| Reproduzierbarkeit | Zuf√§llig oder random_state sporadisch | Konsequentes Seeding & Versionierung (requirements.txt) |
| Fehlerbehandlung | Kaum vorhanden ("Happy Path") | Try-Except Bl√∂cke & Validierung von Input-Daten |
üìã Inhaltsverzeichnis
 * üîç Ziele: Small Data vs. Big Data
 * üìÅ Projekt-√úbersicht & Ordnerstruktur
 * üõ†Ô∏è Technischer Stack
 * üöÄ Installation & Quickstart
 * üìö Die Fallstudien (Case Studies)
 * üîÑ Der ML-Workflow 2026
 * üìù Lizenz & Credits
üîç Ziele: Small Data vs. Big Data
Wie im urspr√ºnglichen Repository bleibt das Kernziel der Vergleich zweier Welten, jedoch mit modernisierten Werkzeugen:
 * Small Data (Scikit-Learn/Pandas): Fokus auf In-Memory Verarbeitung, komplexe Feature-Engineering-Pipelines und schnelle Iterationszyklen. Ideal f√ºr Datens√§tze, die in den Arbeitsspeicher passen (z.B. AirBnB Listings).
 * Big Data (Apache Spark): Fokus auf Skalierbarkeit und verteiltes Rechnen. (Hinweis: Die Spark-Beispiele werden derzeit in separate Docker-Container ausgelagert, um die lokale Umgebung schlank zu halten).
üìÅ Projekt-√úbersicht & Ordnerstruktur
Die Struktur wurde bereinigt, um Legacy-Dateien klar von modernem Code zu trennen.
Machine-Learning-with-Python-Upgrade-2026/
‚îú‚îÄ‚îÄ üìÑ README.md                 # Diese Dokumentation
‚îú‚îÄ‚îÄ üìÑ requirements.txt          # Gepinne Versionen f√ºr Reproduzierbarkeit
‚îú‚îÄ‚îÄ üìÑ CHANGELOG.md              # Historie der √Ñnderungen
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                     # Detaillierte Dokumentation der Case Studies
‚îÇ   ‚îú‚îÄ‚îÄ MOVIES_PREDICT_NANS.md
‚îÇ   ‚îú‚îÄ‚îÄ MOVIES_STRATIFIED_SAMPLE.md
‚îÇ   ‚îî‚îÄ‚îÄ AIRBNB_PRICE_PREDICTION.md
‚îÇ
‚îú‚îÄ‚îÄ üìÇ datasets/                 # Rohdaten (lokal gespeichert)
‚îÇ   ‚îú‚îÄ‚îÄ AirBnB/
‚îÇ   ‚îî‚îÄ‚îÄ movies/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/                # Modernisierte Jupyter Notebooks
‚îÇ   ‚îî‚îÄ‚îÄ movies/                 # Z.B. NaN-Prediction mit DecisionTrees
‚îÇ
‚îú‚îÄ‚îÄ üìÇ scripts/                  # Produktionsreife Python-Skripte
‚îÇ   ‚îî‚îÄ‚îÄ Sklearn_MachineLearning_AirBnB.py  # Hauptskript (Refactored)
‚îÇ
‚îî‚îÄ‚îÄ üìÇ legacy/                   # Archiv (Der alte Code von 2020 zum Vergleich)
    ‚îú‚îÄ‚îÄ old_notebooks/
    ‚îî‚îÄ‚îÄ old_scripts/

üõ†Ô∏è Technischer Stack
Dieses Upgrade setzt auf Stabilit√§t und aktuelle APIs (Stand 2026).
 * Python: >= 3.10
 * Pandas: >= 2.0 (Nutzung neuer dtypes und PyArrow Backend wo m√∂glich)
 * Scikit-Learn: >= 1.2 (Nutzung von set_config(transform_output="pandas") f√ºr bessere Lesbarkeit)
 * Visualisierung: Matplotlib & Seaborn (aktualisierte Styles)
 * Qualit√§tssicherung: flake8 konformer Code-Stil und Type Hinting.
üöÄ Installation & Quickstart
Wir nutzen venv f√ºr eine isolierte, saubere Umgebung.
1. Repository klonen
git clone [https://github.com/AndreasTraut/Machine-Learning-with-Python-Upgrade-2026.git](https://github.com/AndreasTraut/Machine-Learning-with-Python-Upgrade-2026.git)
cd Machine-Learning-with-Python-Upgrade-2026

2. Virtuelle Umgebung erstellen
python3 -m venv venv

3. Aktivieren
 * Windows: venv\Scripts\activate
 * Mac/Linux: source venv/bin/activate
4. Abh√§ngigkeiten installieren
pip install -r requirements.txt

5. Skript ausf√ºhren (Beispiel AirBnB)
python scripts/Sklearn_MachineLearning_AirBnB.py

üìö Die Fallstudien (Case Studies)
1. AirBnB Preisvorhersage (Full ML Pipeline)
 * Pfad: scripts/Sklearn_MachineLearning_AirBnB.py
 * Das Upgrade: Urspr√ºnglich ein langes Skript, ist dies nun eine modulare Applikation.
   * Einsatz von ColumnTransformer f√ºr gemischte Datentypen.
   * Robuster Umgang mit fehlenden Werten durch iterative Imputer statt simplem Mean.
   * Ausf√ºhrliches Logging statt Print-Statements.
   * Doku: Siehe docs/AIRBNB_PRICE_PREDICTION.md
2. Movies Database (Predicting NaNs)
 * Pfad: notebooks/movies/
 * Das Upgrade: Demonstration, wie man fehlende Werte (Revenue) nicht einfach "auff√ºllt", sondern mittels ML vorhersagt.
   * Vergleich von Stratified Sampling vs. Random Sampling.
   * Einsatz von DecisionTrees zur Imputation.
   * Doku: Siehe docs/MOVIES_PREDICT_NANS.md
üîÑ Der ML-Workflow 2026
Der Code in diesem Repository folgt strikt diesem Schema:
 * Ingestion: Typ-sicheres Laden der Daten mit Fehlerbehandlung.
 * EDA (Exploratory Data Analysis): Visuelle Inspektion der Verteilungen und Korrelationen.
 * Preprocessing Pipeline:
   * Categorical: OneHotEncoding (mit handle_unknown='ignore' f√ºr Produktionssicherheit).
   * Numerical: StandardScaler & Imputation.
 * Training: GridSearch oder RandomizedSearch f√ºr Hyperparameter-Tuning.
 * Evaluation: Metriken (RMSE, R¬≤) und Residual-Analyse.
 * Persistenz: Speichern des trainierten Modells mittels joblib f√ºr sp√§teren Einsatz.
üìù Lizenz & Credits
Dieses Projekt basiert auf dem urspr√ºnglichen Werk von Andreas Traut.
Lizenziert unter der Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.
Wir freuen uns √ºber Feedback, Pull Requests und Diskussionen dar√ºber, wie sich ML-Engineering weiterentwickelt!
