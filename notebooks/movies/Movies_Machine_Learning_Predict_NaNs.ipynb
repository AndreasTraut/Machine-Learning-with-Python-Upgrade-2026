{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Machine Learning - Predict NaNs (Upgrade 2025)\n",
    "\n",
    "**Autor:** Andreas Traut  \n",
    "**Datum:** Dezember 2025  \n",
    "**Version:** 2025.1\n",
    "\n",
    "## Ziel\n",
    "\n",
    "Dieses Notebook zeigt, wie fehlende Werte (NaNs) in der Spalte \"Revenue\" eines Filmdatensatzes vorhergesagt werden k√∂nnen.\n",
    "\n",
    "## Aktualisierungen (2025)\n",
    "\n",
    "- ‚úÖ Python 3.10+ kompatibel\n",
    "- ‚úÖ scikit-learn >= 1.2 APIs\n",
    "- ‚úÖ SimpleImputer statt deprecated Imputer\n",
    "- ‚úÖ OneHotEncoder mit `handle_unknown='ignore'`\n",
    "- ‚úÖ StandardScaler in Pipeline\n",
    "- ‚úÖ random_state f√ºr Reproduzierbarkeit\n",
    "- ‚úÖ Moderner, modularer Code\n",
    "\n",
    "## Anforderungen\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn matplotlib seaborn jupyterlab\n",
    "```\n",
    "\n",
    "## Datenquelle\n",
    "\n",
    "**Kaggle:** [IMDB 10000+ Movies Dataset](https://www.kaggle.com/datasets)\n",
    "\n",
    "Bitte laden Sie die Daten herunter und speichern Sie sie unter: `datasets/movies/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup und Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard-Bibliotheken\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Data Science Bibliotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Konfiguration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualisierung\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Alle Bibliotheken erfolgreich importiert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zum Dataset\n",
    "data_path = Path('../../datasets/movies/movies.csv')\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(\"‚ö†Ô∏è Dataset nicht gefunden!\")\n",
    "    print(f\"Bitte laden Sie die Daten herunter und speichern Sie sie unter: {data_path}\")\n",
    "    print(\"Quelle: https://www.kaggle.com/datasets\")\n",
    "else:\n",
    "    # Daten laden\n",
    "    movies_df = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Daten geladen: {movies_df.shape[0]} Zeilen, {movies_df.shape[1]} Spalten\")\n",
    "    \n",
    "    # Erste Zeilen anzeigen\n",
    "    display(movies_df.head())\n",
    "    \n",
    "    # Info √ºber Dataset\n",
    "    print(\"\\nüìä Dataset Info:\")\n",
    "    movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistische Zusammenfassung\n",
    "print(\"üìà Statistische Zusammenfassung:\")\n",
    "display(movies_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte analysieren\n",
    "print(\"‚ùì Fehlende Werte:\")\n",
    "missing_values = movies_df.isnull().sum()\n",
    "missing_percent = 100 * missing_values / len(movies_df)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Anzahl': missing_values,\n",
    "    'Prozent': missing_percent\n",
    "})\n",
    "display(missing_df[missing_df['Anzahl'] > 0].sort_values('Anzahl', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Revenue Distribution\n",
    "if 'Revenue' in movies_df.columns:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    movies_df['Revenue'].dropna().hist(bins=50, edgecolor='black')\n",
    "    plt.xlabel('Revenue')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Revenue Distribution')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    movies_df['Revenue'].dropna().plot(kind='box')\n",
    "    plt.ylabel('Revenue')\n",
    "    plt.title('Revenue Box Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Daten mit und ohne NaN in Revenue\n",
    "if 'Revenue' in movies_df.columns:\n",
    "    # Daten MIT Revenue-Werten (f√ºr Training)\n",
    "    movies_with_revenue = movies_df[movies_df['Revenue'].notna()].copy()\n",
    "    \n",
    "    # Daten OHNE Revenue-Werte (f√ºr Vorhersage)\n",
    "    movies_without_revenue = movies_df[movies_df['Revenue'].isna()].copy()\n",
    "    \n",
    "    print(f\"‚úÖ Daten mit Revenue: {len(movies_with_revenue)} Zeilen\")\n",
    "    print(f\"‚ö†Ô∏è Daten ohne Revenue (NaN): {len(movies_without_revenue)} Zeilen\")\n",
    "    \n",
    "    # Features f√ºr Modellierung ausw√§hlen\n",
    "    # Numerische Features\n",
    "    numeric_features = ['Year', 'Score', 'Metascore', 'Vote', 'Runtime']\n",
    "    numeric_features = [f for f in numeric_features if f in movies_df.columns]\n",
    "    \n",
    "    # Kategorische Features\n",
    "    categorical_features = ['Genre', 'Director']\n",
    "    categorical_features = [f for f in categorical_features if f in movies_df.columns]\n",
    "    \n",
    "    print(f\"\\nüìä Features:\")\n",
    "    print(f\"Numerisch ({len(numeric_features)}): {numeric_features}\")\n",
    "    print(f\"Kategorisch ({len(categorical_features)}): {categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Revenue' in movies_df.columns and len(movies_with_revenue) > 0:\n",
    "    # Features und Labels\n",
    "    all_features = numeric_features + categorical_features\n",
    "    X = movies_with_revenue[all_features]\n",
    "    y = movies_with_revenue['Revenue']\n",
    "    \n",
    "    # Train-Test Split mit random_state f√ºr Reproduzierbarkeit\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Train-Test Split erstellt:\")\n",
    "    print(f\"Training Set: {X_train.shape}\")\n",
    "    print(f\"Test Set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Pipeline erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerische Pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Kategorische Pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Kombinierte Pipeline mit ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Preprocessing Pipeline erstellt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modelle trainieren und evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "if 'X_train' in locals():\n",
    "    print(\"üå≤ Training Decision Tree Regressor...\")\n",
    "    \n",
    "    # Pipeline: Preprocessing + Model\n",
    "    tree_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', DecisionTreeRegressor(random_state=42, max_depth=10))\n",
    "    ])\n",
    "    \n",
    "    # Training\n",
    "    tree_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen\n",
    "    y_pred_train = tree_pipeline.predict(X_train)\n",
    "    y_pred_test = tree_pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"\\nüìä Decision Tree Results:\")\n",
    "    print(f\"Train RMSE: {train_rmse:,.2f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:,.2f}\")\n",
    "    print(f\"Test R¬≤: {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "if 'X_train' in locals():\n",
    "    print(\"üå≥ Training Random Forest Regressor...\")\n",
    "    \n",
    "    # Pipeline: Preprocessing + Model\n",
    "    forest_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Training\n",
    "    forest_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen\n",
    "    y_pred_train = forest_pipeline.predict(X_train)\n",
    "    y_pred_test = forest_pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"\\nüìä Random Forest Results:\")\n",
    "    print(f\"Train RMSE: {train_rmse:,.2f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:,.2f}\")\n",
    "    print(f\"Test R¬≤: {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation f√ºr Random Forest\n",
    "if 'forest_pipeline' in locals():\n",
    "    print(\"üîÑ Performing Cross-Validation...\")\n",
    "    \n",
    "    cv_scores = cross_val_score(\n",
    "        forest_pipeline,\n",
    "        X_train, y_train,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "    \n",
    "    print(f\"\\nüìä Cross-Validation Results (5-fold):\")\n",
    "    print(f\"RMSE Scores: {cv_rmse_scores}\")\n",
    "    print(f\"Mean RMSE: {cv_rmse_scores.mean():,.2f}\")\n",
    "    print(f\"Std RMSE: {cv_rmse_scores.std():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Vorhersage f√ºr NaN-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen f√ºr Filme ohne Revenue\n",
    "if 'movies_without_revenue' in locals() and len(movies_without_revenue) > 0:\n",
    "    print(f\"üîÆ Vorhersage f√ºr {len(movies_without_revenue)} Filme ohne Revenue...\")\n",
    "    \n",
    "    # Features vorbereiten\n",
    "    X_predict = movies_without_revenue[all_features]\n",
    "    \n",
    "    # Vorhersagen\n",
    "    predicted_revenue = forest_pipeline.predict(X_predict)\n",
    "    \n",
    "    # Ergebnisse hinzuf√ºgen\n",
    "    movies_without_revenue['Predicted_Revenue'] = predicted_revenue\n",
    "    \n",
    "    print(\"\\n‚úÖ Vorhersagen abgeschlossen!\")\n",
    "    print(\"\\nBeispiele:\")\n",
    "    if 'Title' in movies_without_revenue.columns:\n",
    "        display(movies_without_revenue[['Title', 'Year', 'Predicted_Revenue']].head(10))\n",
    "    else:\n",
    "        display(movies_without_revenue[['Predicted_Revenue']].head(10))\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Keine Filme ohne Revenue gefunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Modell speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "if 'forest_pipeline' in locals():\n",
    "    model_path = 'movies_revenue_predictor.pkl'\n",
    "    joblib.dump(forest_pipeline, model_path)\n",
    "    print(f\"‚úÖ Modell gespeichert: {model_path}\")\n",
    "    \n",
    "    # Modell laden (Test)\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Modell erfolgreich geladen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Zusammenfassung\n",
    "\n",
    "In diesem Notebook haben wir:\n",
    "\n",
    "1. ‚úÖ Daten geladen und exploriert\n",
    "2. ‚úÖ Fehlende Werte analysiert\n",
    "3. ‚úÖ Preprocessing Pipeline erstellt (moderne APIs)\n",
    "4. ‚úÖ Decision Tree und Random Forest Modelle trainiert\n",
    "5. ‚úÖ Cross-Validation durchgef√ºhrt\n",
    "6. ‚úÖ NaN-Werte vorhergesagt\n",
    "7. ‚úÖ Modell gespeichert\n",
    "\n",
    "### Wichtige Aktualisierungen (2025):\n",
    "\n",
    "- `SimpleImputer` statt deprecated `Imputer`\n",
    "- `OneHotEncoder` mit `handle_unknown='ignore'`\n",
    "- `StandardScaler` in Pipeline\n",
    "- `random_state` f√ºr Reproduzierbarkeit\n",
    "- Moderne Pipeline-Struktur mit `ColumnTransformer`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
